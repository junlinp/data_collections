FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements_crawler.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements_crawler.txt

# Copy application code
COPY crawler_logic.py .
COPY url_manager.py .
COPY config.py .
COPY memory_utils.py .
COPY ./*.py .

# Create data directory for databases
RUN mkdir -p /app/data

# Set environment variables
ENV CRAWLER_PORT=5001
ENV DEBUG=False

# Expose port
EXPOSE 5001

# Copy the crawler server
COPY crawler_server.py .

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:5001/api/health || exit 1

# Run the crawler server
CMD ["python", "crawler_server.py"]

ARG http_proxy
ARG https_proxy
ARG HTTP_PROXY
ARG HTTPS_PROXY
ENV http_proxy=$http_proxy
ENV https_proxy=$https_proxy
ENV HTTP_PROXY=$HTTP_PROXY
ENV HTTPS_PROXY=$HTTPS_PROXY 