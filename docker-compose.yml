version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: web-crawler-mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password123
      - MONGO_INITDB_DATABASE=crawler_db
    volumes:
      - /mnt/rbd0/crawler_data/mongodb:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - crawler-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  crawler:
    build:
      context: .
      dockerfile: Dockerfile.crawler
      args:
        - http_proxy=http://192.168.31.22:10808
        - https_proxy=http://192.168.31.22:10808
        - HTTP_PROXY=http://192.168.31.22:10808
        - HTTPS_PROXY=http://192.168.31.22:10808
    container_name: web-crawler-server
    ports:
      - "5001:5001"
    environment:
      - CRAWLER_PORT=5001
      - DEBUG=False
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
      - NO_PROXY=localhost,127.0.0.1,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16,redis,crawler,web-crawler-server,data_collections-redis-1,mongodb,web-crawler-mongodb
      - no_proxy=localhost,127.0.0.1,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16,redis,crawler,web-crawler-server,data_collections-redis-1,mongodb,web-crawler-mongodb
      - MONGODB_URI=mongodb://admin:password123@mongodb:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    networks:
      - crawler-network
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; response = requests.get('http://localhost:5001/api/health'); exit(0 if response.status_code == 200 else 1)"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 40s

  unified-web:
    build:
      context: .
      dockerfile: Dockerfile.unified
      args:
        - http_proxy=http://192.168.31.22:10808
        - https_proxy=http://192.168.31.22:10808
        - HTTP_PROXY=http://192.168.31.22:10808
        - HTTPS_PROXY=http://192.168.31.22:10808
    container_name: unified-web-service
    ports:
      - "5000:5000"
    environment:
      - UNIFIED_PORT=5000
      - CRAWLER_SERVER_URL=http://crawler:5001
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DEBUG=False
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
      - no_proxy=localhost,127.0.0.1,crawler,web-crawler-server,mongodb,web-crawler-mongodb,redis,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16
      - NO_PROXY=localhost,127.0.0.1,crawler,web-crawler-server,mongodb,web-crawler-mongodb,redis,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16
      - MONGODB_URI=mongodb://admin:password123@mongodb:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
      - LOCAL_LLM_URL=http://host.docker.internal:11434
      - LOCAL_LLM_MODEL=deepseek-r1:latest
    depends_on:
      mongodb:
        condition: service_healthy
      crawler:
        condition: service_healthy
      redis:
        condition: service_started
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    networks:
      - crawler-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    environment:
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
    networks:
      - crawler-network

  test:
    image: data_collections-crawler
    build:
      context: .
      dockerfile: Dockerfile.crawler
    volumes:
      - .:/app
    command: python3 -m unittest discover
    depends_on:
      - redis
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379

volumes:
  crawler_data:
  redis_data:

networks:
  crawler-network:
    driver: bridge 