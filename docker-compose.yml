version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: web-crawler-mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password123
      - MONGO_INITDB_DATABASE=crawler_db
    volumes:
      - /mnt/rbd0/crawler_data/mongodb:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - crawler-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  crawler:
    build:
      context: .
      dockerfile: Dockerfile.crawler
      args:
        - http_proxy=http://192.168.31.22:10808
        - https_proxy=http://192.168.31.22:10808
        - HTTP_PROXY=http://192.168.31.22:10808
        - HTTPS_PROXY=http://192.168.31.22:10808
    container_name: web-crawler-server
    ports:
      - "5001:5001"
    environment:
      - CRAWLER_PORT=5001
      - DEBUG=False
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
      - NO_PROXY=localhost,127.0.0.1,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16,redis,crawler,web-crawler-server,data_collections-redis-1,mongodb,web-crawler-mongodb
      - no_proxy=localhost,127.0.0.1,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16,redis,crawler,web-crawler-server,data_collections-redis-1,mongodb,web-crawler-mongodb
      - MONGODB_URI=mongodb://admin:password123@mongodb:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    networks:
      - crawler-network
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5001/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
      args:
        - http_proxy=http://192.168.31.22:10808
        - https_proxy=http://192.168.31.22:10808
        - HTTP_PROXY=http://192.168.31.22:10808
        - HTTPS_PROXY=http://192.168.31.22:10808
    container_name: web-crawler-ui
    ports:
      - "5002:5002"
    environment:
      - UI_PORT=5002
      - CRAWLER_SERVER_URL=http://crawler:5001
      - DEBUG=False
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
      - no_proxy=localhost,127.0.0.1,crawler,web-crawler-server,mongodb,web-crawler-mongodb,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16
      - NO_PROXY=localhost,127.0.0.1,crawler,web-crawler-server,mongodb,web-crawler-mongodb,172.18.0.0/16,10.0.0.0/8,192.168.0.0/16
      - MONGODB_URI=mongodb://admin:password123@mongodb:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
    depends_on:
      mongodb:
        condition: service_healthy
      crawler:
        condition: service_healthy
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    networks:
      - crawler-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5002/')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  llm-processor:
    build:
      context: .
      dockerfile: Dockerfile.llm
    container_name: web-llm-processor
    network_mode: host
    environment:
      - LLM_PORT=5003
      - DEBUG=False
      - MONGODB_URI=mongodb://admin:password123@localhost:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
      - LOCAL_LLM_URL=http://localhost:11434
      - LOCAL_LLM_MODEL=deepseek-r1:latest
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    depends_on:
      mongodb:
        condition: service_healthy
      crawler:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5003/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  summary-display:
    build:
      context: .
      dockerfile: Dockerfile.summary
    container_name: web-summary-display
    network_mode: host
    environment:
      - SUMMARY_PORT=5004
      - DEBUG=False
      - MONGODB_URI=mongodb://admin:password123@localhost:27017/crawler_db?authSource=admin
      - MONGODB_DATABASE=crawler_db
      - LLM_PROCESSOR_URL=http://localhost:5003
    volumes:
      - /mnt/rbd0/crawler_data:/app/data
    depends_on:
      mongodb:
        condition: service_healthy
      llm-processor:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5004/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    environment:
      - http_proxy=http://192.168.31.22:10808
      - https_proxy=http://192.168.31.22:10808
      - HTTP_PROXY=http://192.168.31.22:10808
      - HTTPS_PROXY=http://192.168.31.22:10808
    networks:
      - crawler-network

  test:
    image: data_collections-crawler
    build:
      context: .
      dockerfile: Dockerfile.crawler
    volumes:
      - .:/app
    command: python3 -m unittest discover
    depends_on:
      - redis
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379

volumes:
  crawler_data:
  redis_data:

networks:
  crawler-network:
    driver: bridge 